---
---

@string{Interspeech = {Conference of the International Speech Communication Association (InterSpeech),}}
@string{ICASSP = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),}}
@string{ASRU = {IEEE Automatic Speech Recognition and Understanding Workshop (ASRU),}}
@string{SLT = {IEEE Spoken Language Technology Workshop (SLT),}}
@string{TASLP = {IEEE/ACM Transactions on Audio, Speech, and Language Processing,}}
@string{NeurIPS = {Advances in Neural Information Processing Systems}}


@article{yang2021superb,
  title={SUPERB: Speech processing Universal PERformance Benchmark},
  author={Yang, Shu-wen and Chi, Po-Han and Chuang, Yung-Sung and Lai, Cheng-I Jeff and Lakhotia, Kushal and Lin, Yist Y and Liu, Andy T and Shi, Jiatong and Chang, Xuankai and Lin, Guan-Ting and others},
  journal={arXiv preprint arXiv:2105.01051},
  year={2021}
}

@inproceedings{chang2021hypothesis,
  title={Hypothesis Stitcher for End-to-End Speaker-attributed ASR on Long-form Multi-talker Recordings},
  author={Chang, Xuankai and Kanda, Naoyuki and Gaur, Yashesh and Wang, Xiaofei and Meng, Zhong and Yoshioka, Takuya},
  booktitle=ICASSP,
  year={2021},
  organization={IEEE}
}

@inproceedings{guo2021recent,
  title={Recent developments on espnet toolkit boosted by conformer},
  author={Guo, Pengcheng and Boyer, Florian and Chang, Xuankai and Hayashi, Tomoki and Higuchi, Yosuke and Inaguma, Hirofumi and Kamo, Naoyuki and Li, Chenda and Garcia-Romero, Daniel and Shi, Jiatong and others},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5874--5878},
  year={2021},
  organization={IEEE}
}

@article{watanabe20202020,
  title={The 2020 ESPnet update: new features, broadened applications, performance improvements, and future plans},
  author={Watanabe, Shinji and Boyer, Florian and Chang, Xuankai and Guo, Pengcheng and Hayashi, Tomoki and Higuchi, Yosuke and Hori, Takaaki and Huang, Wen-Chin and Inaguma, Hirofumi and Kamo, Naoyuki and others},
  journal={arXiv preprint arXiv:2012.13006},
  year={2020}
}

@inproceedings{shi2021highland,
  title={Highland Puebla Nahuatl Speech Translation Corpus for Endangered Language Documentation},
  author={Shi, Jiatong and Amith, Jonathan D and Chang, Xuankai and Dalmia, Siddharth and Yan, Brian and Watanabe, Shinji},
  booktitle={Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas},
  pages={53--63},
  year={2021}
}

@inproceedings{li2021espnet,
  title={ESPnet-SE: end-to-end speech enhancement and separation toolkit designed for ASR integration},
  author={Li, Chenda and Shi, Jing and Zhang, Wangyou and Subramanian, Aswin Shanmugam and Chang, Xuankai and Kamo, Naoyuki and Hira, Moto and Hayashi, Tomoki and Boeddeker, Christoph and Chen, Zhuo and others},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)},
  pages={785--792},
  year={2021},
  organization={IEEE}
}

@inproceedings{kanda2021investigation,
  title={Investigation of end-to-end speaker-attributed ASR for continuous multi-talker recordings},
  author={Kanda, Naoyuki and Chang, Xuankai and Gaur, Yashesh and Wang, Xiaofei and Meng, Zhong and Chen, Zhuo and Yoshioka, Takuya},
  booktitle=SLT,
  pages={809--816},
  year={2021},
  organization={IEEE}
}

@article{shi2020sequence,
  title={Sequence to Multi-Sequence Learning via Conditional Chain Mapping for Mixture Signals},
  author={Shi, Jing and Chang, Xuankai and Guo, Pengcheng and Watanabe, Shinji and Fujita, Yusuke and Xu, Jiaming and Xu, Bo and Xie, Lei},
  journal=NeurIPS,
  volume={33},
  year={2020}
}

@article{zhang2020end,
  title={End-to-End Far-Field Speech Recognition with Unified Dereverberation and Beamforming},
  author={Zhang, Wangyou and Subramanian, Aswin Shanmugam and Chang, Xuankai and Watanabe, Shinji and Qian, Yanmin},
  journal={Proc. Interspeech 2020},
  pages={324--328},
  year={2020}
}

@inproceedings{chang2020end,
  title={End-to-end multi-speaker speech recognition with transformer},
  author={Chang, Xuankai and Zhang, Wangyou and Qian, Yanmin and Le Roux, Jonathan and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={6134--6138},
  year={2020},
  organization={IEEE}
}

@article{watanabe2020chime,
  title={CHiME-6 challenge: Tackling multispeaker speech recognition for unsegmented recordings},
  author={Watanabe, Shinji and Mandel, Michael and Barker, Jon and Vincent, Emmanuel and Arora, Ashish and Chang, Xuankai and Khudanpur, Sanjeev and Manohar, Vimal and Povey, Daniel and Raj, Desh and others},
  journal={arXiv preprint arXiv:2004.09249},
  year={2020}
}

@article{zhang2020improving,
  title={Improving end-to-end single-channel multi-talker speech recognition},
  author={Zhang, Wangyou and Chang, Xuankai and Qian, Yanmin and Watanabe, Shinji},
  journal=TASLP,
  volume={28},
  pages={1385--1394},
  year={2020},
  publisher={IEEE}
}

@article{chang2020end,
  title={End-to-End ASR with Adaptive Span Self-Attention},
  author={Chang, Xuankai and Subramanian, Aswin Shanmugam and Guo, Pengcheng and Watanabe, Shinji and Fujita, Yuya and Omachi, Motoi},
  journal={Proc. Interspeech 2020},
  pages={3595--3599},
  year={2020}
}

@inproceedings{chang2019mimo,
  title={MIMO-Speech: End-to-end multi-channel multi-speaker speech recognition},
  author={Chang, Xuankai and Zhang, Wangyou and Qian, Yanmin and Le Roux, Jonathan and Watanabe, Shinji},
  booktitle=ASRU,
  pages={237--244},
  year={2019},
  organization={IEEE}
}

@inproceedings{chang2019end,
  title={End-to-end monaural multi-speaker ASR system without pretraining},
  author={Chang, Xuankai and Qian, Yanmin and Yu, Kai and Watanabe, Shinji},
  booktitle=ICASSP,
  pages={6256--6260},
  year={2019},
  organization={IEEE}
}

@article{zhang2019knowledge,
  title={Knowledge Distillation for End-to-End Monaural Multi-Talker ASR System$},
  author={Zhang, Wangyou and Chang, Xuankai and Qian, Yanmin},
  journal=Interspeech,
  pages={2633--2637},
  year={2019}
}

@article{qian2018single,
  title={Single-channel multi-talker speech recognition with permutation invariant training},
  author={Qian, Yanmin and Chang, Xuankai and Yu, Dong},
  journal={Speech Communication},
  volume={104},
  pages={1--11},
  year={2018},
  publisher={Elsevier}
}

@article{chang2018monaural,
  title={Monaural Multi-Talker Speech Recognition with Attention Mechanism and Gated Convolutional Networks},
  author={Chang, Xuankai and Qian, Yanmin and Yu, Dong},
  journal=Interspeech,
  pages={1586--1590},
  year={2018}
}

@inproceedings{chang2018adaptive,
  title={Adaptive permutation invariant training with auxiliary information for monaural multi-talker speech recognition},
  author={Chang, Xuankai and Qian, Yanmin and Yu, Dong},
  booktitle=ICASSP,
  pages={5974--5978},
  year={2018},
  organization={IEEE}
}

@article{qian2018past,
  title={Past review, current progress, and challenges ahead on the cocktail party problem},
  author={Qian, Yan-min and Weng, Chao and Chang, Xuan-kai and Wang, Shuai and Yu, Dong},
  journal={Frontiers of Information Technology & Electronic Engineering},
  volume={19},
  number={1},
  pages={40--63},
  year={2018},
  publisher={Springer}
}

@article{yu2017recognizing,
  title={Recognizing Multi-Talker Speech with Permutation Invariant Training},
  author={Yu, Dong and Chang, Xuankai and Qian, Yanmin},
  journal=Interspeech,
  pages={2456--2460},
  year={2017}
}

@inproceedings{zhuang2016unrestricted,
  title={Unrestricted Vocabulary Keyword Spotting Using LSTM-CTC.},
  author={Zhuang, Yimeng and Chang, Xuankai and Qian, Yanmin and Yu, Kai},
  booktitle=Interspeech,
  pages={938--942},
  year={2016}
}
